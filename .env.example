# MedEducation Environment Configuration

# LLM Settings (Ollama default)
LOCAL_LLM_BASE_URL=http://localhost:11434/v1
LOCAL_LLM_MODEL=qwen3:14b

# Optional: API key if using a service that requires it
# LOCAL_LLM_API_KEY=your-api-key

# Disable tokenizer parallelism warnings
TOKENIZERS_PARALLELISM=false
